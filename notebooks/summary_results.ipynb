{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b21ffcdf",
   "metadata": {},
   "source": [
    "# HMIN 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c71f57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260\n",
      "       sample prediction_id  affinity_probability_binary\n",
      "0  hmin_b4_r3        s_1802                     0.225867\n",
      "1  hmin_b4_r3        s_1683                     0.153770\n",
      "2  hmin_b4_r3        s_1427                     0.232740\n",
      "3  hmin_b4_r3         s_112                     0.202494\n",
      "4  hmin_b4_r3        s_1915                     0.079839\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "records = []\n",
    "\n",
    "for x1 in os.listdir('../results'):\n",
    "    if not x1.startswith('hmin_'):\n",
    "        continue  # пропускаем все, кто не начинается на hmin_\n",
    "    pred_dir = os.path.join('../results', x1, 'boltz_results_balanced_64_'+x1[-2:], 'predictions')\n",
    "    if not os.path.isdir(pred_dir):\n",
    "        continue\n",
    "\n",
    "    for x3 in os.listdir(pred_dir):\n",
    "\n",
    "        json_path = os.path.join(pred_dir, x3, f'affinity_{x3}.json')\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path, 'r') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                    if isinstance(data, dict):\n",
    "                        # Add metadata to each record, such as folder names\n",
    "                        data['sample'] = x1\n",
    "                        data['prediction_id'] = x3\n",
    "                        records.append(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Failed to decode JSON in {json_path}\")\n",
    "        else:\n",
    "            print(f\"JSON not found: {json_path}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "df = df[['sample', 'prediction_id', 'affinity_probability_binary']]\n",
    "print(df.shape[0])\n",
    "print(df.head())\n",
    "\n",
    "os.makedirs('../results_summary', exist_ok=True)\n",
    "df.to_csv('../results_summary/hmin.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "094a432e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "                   step  seconds       source\n",
      "0  structure_prediction   329.44   hmin_b4_r3\n",
      "1   affinity_prediction   198.70   hmin_b4_r3\n",
      "2  structure_prediction   348.67   hmin_b2_r3\n",
      "3   affinity_prediction   219.40   hmin_b2_r3\n",
      "4  structure_prediction   349.99  hmin_b16_r3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "records = []\n",
    "\n",
    "for x1 in os.listdir('../results'):\n",
    "    if not x1.startswith('hmin_'):\n",
    "        continue  # пропускаем все, кто не начинается на hmin_\n",
    "    pred_dir = os.path.join('../results', x1, 'boltz_results_balanced_64_' + x1[-2:])\n",
    "    if not os.path.isdir(pred_dir):\n",
    "        continue\n",
    "    else:\n",
    "        time_path = os.path.join(pred_dir, 'time.tsv')\n",
    "        if os.path.exists(time_path):\n",
    "            df = pd.read_csv(time_path, sep='\\t')\n",
    "            # Можно добавить информацию о том, из какой это папки\n",
    "            df['source'] = x1\n",
    "            records.append(df)\n",
    "\n",
    "# Объединение всех таблиц в одну\n",
    "combined_df = pd.concat(records, ignore_index=True)\n",
    "\n",
    "# Вывод итогового датафрейма\n",
    "print(combined_df.shape[0])\n",
    "print(combined_df.head())\n",
    "\n",
    "os.makedirs('../results_summary', exist_ok=True)\n",
    "combined_df.to_csv('../results_summary/hmin_time.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cfd9d",
   "metadata": {},
   "source": [
    "# HBASE 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76c4cf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1260\n",
      "        sample prediction_id  affinity_probability_binary\n",
      "0  hbase_b1_r1        s_1253                     0.251276\n",
      "1  hbase_b1_r1        s_1483                     0.269246\n",
      "2  hbase_b1_r1        s_1356                     0.268604\n",
      "3  hbase_b1_r1        s_1766                     0.287859\n",
      "4  hbase_b1_r1         s_315                     0.184288\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "records = []\n",
    "\n",
    "for x1 in os.listdir('../results'):\n",
    "    if not x1.startswith('hbase_'):\n",
    "        continue  # пропускаем все, кто не начинается на hmin_\n",
    "    pred_dir = os.path.join('../results', x1, 'boltz_results_balanced_64_'+x1[-2:], 'predictions')\n",
    "    if not os.path.isdir(pred_dir):\n",
    "        continue\n",
    "\n",
    "    for x3 in os.listdir(pred_dir):\n",
    "\n",
    "        json_path = os.path.join(pred_dir, x3, f'affinity_{x3}.json')\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path, 'r') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                    if isinstance(data, dict):\n",
    "                        # Add metadata to each record, such as folder names\n",
    "                        data['sample'] = x1\n",
    "                        data['prediction_id'] = x3\n",
    "                        records.append(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Failed to decode JSON in {json_path}\")\n",
    "        else:\n",
    "            print(f\"JSON not found: {json_path}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "df = df[['sample', 'prediction_id', 'affinity_probability_binary']]\n",
    "print(df.shape[0])\n",
    "print(df.head())\n",
    "\n",
    "os.makedirs('../results_summary', exist_ok=True)\n",
    "df.to_csv('../results_summary/hbase.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c722c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "                   step  seconds       source\n",
      "0  structure_prediction   737.28  hbase_b1_r1\n",
      "1   affinity_prediction   458.75  hbase_b1_r1\n",
      "2  structure_prediction   661.25  hbase_b2_r3\n",
      "3   affinity_prediction   381.91  hbase_b2_r3\n",
      "4  structure_prediction   592.59  hbase_b8_r2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "records = []\n",
    "\n",
    "for x1 in os.listdir('../results'):\n",
    "    if not x1.startswith('hbase_'):\n",
    "        continue  # пропускаем все, кто не начинается на hmin_\n",
    "    pred_dir = os.path.join('../results', x1, 'boltz_results_balanced_64_' + x1[-2:])\n",
    "    if not os.path.isdir(pred_dir):\n",
    "        continue\n",
    "    else:\n",
    "        time_path = os.path.join(pred_dir, 'time.tsv')\n",
    "        if os.path.exists(time_path):\n",
    "            df = pd.read_csv(time_path, sep='\\t')\n",
    "            # Можно добавить информацию о том, из какой это папки\n",
    "            df['source'] = x1\n",
    "            records.append(df)\n",
    "\n",
    "# Объединение всех таблиц в одну\n",
    "combined_df = pd.concat(records, ignore_index=True)\n",
    "\n",
    "# Вывод итогового датафрейма\n",
    "print(combined_df.shape[0])\n",
    "print(combined_df.head())\n",
    "\n",
    "os.makedirs('../results_summary', exist_ok=True)\n",
    "combined_df.to_csv('../results_summary/hbase_time.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de22dac1",
   "metadata": {},
   "source": [
    "# HLOW 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b04f58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "       sample prediction_id  affinity_probability_binary\n",
      "0  hlow_b2_r0         s_115                     0.229113\n",
      "1  hlow_b2_r0         s_437                     0.441651\n",
      "2  hlow_b2_r0        s_1483                     0.514105\n",
      "3  hlow_b2_r0         s_315                     0.279196\n",
      "4  hlow_b2_r0        s_1933                     0.462134\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "records = []\n",
    "\n",
    "for x1 in os.listdir('../test_results'):\n",
    "    if not x1.startswith('hlow_'):\n",
    "        continue  # пропускаем все, кто не начинается на hmin_\n",
    "    pred_dir = os.path.join('../test_results', x1, 'boltz_results_balanced_64_'+x1[-2:], 'predictions')\n",
    "    if not os.path.isdir(pred_dir):\n",
    "        continue\n",
    "\n",
    "    for x3 in os.listdir(pred_dir):\n",
    "\n",
    "        json_path = os.path.join(pred_dir, x3, f'affinity_{x3}.json')\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path, 'r') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                    if isinstance(data, dict):\n",
    "                        # Add metadata to each record, such as folder names\n",
    "                        data['sample'] = x1\n",
    "                        data['prediction_id'] = x3\n",
    "                        records.append(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Failed to decode JSON in {json_path}\")\n",
    "        else:\n",
    "            print(f\"JSON not found: {json_path}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "df = df[['sample', 'prediction_id', 'affinity_probability_binary']]\n",
    "print(df.shape[0])\n",
    "print(df.head())\n",
    "\n",
    "os.makedirs('../results_summary', exist_ok=True)\n",
    "df.to_csv('../results_summary/hlow.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf07a93",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m records = []\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x1 \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m../results\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x1.startswith(\u001b[33m'\u001b[39m\u001b[33mhlow_\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# пропускаем все, кто не начинается на hmin_\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../results'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "records = []\n",
    "\n",
    "for x1 in os.listdir('../results'):\n",
    "    if not x1.startswith('hlow_'):\n",
    "        continue  # пропускаем все, кто не начинается на hmin_\n",
    "    pred_dir = os.path.join('../results', x1, 'boltz_results_balanced_64_' + x1[-2:])\n",
    "    if not os.path.isdir(pred_dir):\n",
    "        continue\n",
    "    else:\n",
    "        time_path = os.path.join(pred_dir, 'time.tsv')\n",
    "        if os.path.exists(time_path):\n",
    "            df = pd.read_csv(time_path, sep='\\t')\n",
    "            # Можно добавить информацию о том, из какой это папки\n",
    "            df['source'] = x1\n",
    "            records.append(df)\n",
    "\n",
    "# Объединение всех таблиц в одну\n",
    "combined_df = pd.concat(records, ignore_index=True)\n",
    "\n",
    "# Вывод итогового датафрейма\n",
    "print(combined_df.shape[0])\n",
    "print(combined_df.head())\n",
    "\n",
    "os.makedirs('../results_summary', exist_ok=True)\n",
    "combined_df.to_csv('../results_summary/hlow_time.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c534a6",
   "metadata": {},
   "source": [
    "# HMIN ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ee288f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/all_hmin/boltz_results_all/predictions\n",
      "1925\n",
      "     sample prediction_id  affinity_probability_binary\n",
      "0  all_hmin         s_780                     0.212619\n",
      "1  all_hmin          s_16                     0.194154\n",
      "2  all_hmin          s_80                     0.175011\n",
      "3  all_hmin         s_776                     0.193754\n",
      "4  all_hmin         s_391                     0.139325\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "records = []\n",
    "\n",
    "for x1 in os.listdir('../results'):\n",
    "    if not x1.startswith('all_hmin'):\n",
    "        continue  # пропускаем все, кто не начинается на hmin_\n",
    "    pred_dir = os.path.join('../results', x1, 'boltz_results_all', 'predictions')\n",
    "    print(pred_dir)\n",
    "    if not os.path.isdir(pred_dir):\n",
    "        continue\n",
    "    \n",
    "    for x3 in os.listdir(pred_dir):\n",
    "\n",
    "        json_path = os.path.join(pred_dir, x3, f'affinity_{x3}.json')\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path, 'r') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                    if isinstance(data, dict):\n",
    "                        # Add metadata to each record, such as folder names\n",
    "                        data['sample'] = x1\n",
    "                        data['prediction_id'] = x3\n",
    "                        records.append(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Failed to decode JSON in {json_path}\")\n",
    "        else:\n",
    "            print(f\"JSON not found: {json_path}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "df = df[['sample', 'prediction_id', 'affinity_probability_binary']]\n",
    "print(df.shape[0])\n",
    "print(df.head())\n",
    "\n",
    "os.makedirs('../results_summary', exist_ok=True)\n",
    "df.to_csv('../results_summary/all_hmin.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6147dec1",
   "metadata": {},
   "source": [
    "# HBASE ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e92ed38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/all_hbase/boltz_results_all/predictions\n",
      "1925\n",
      "      sample prediction_id  affinity_probability_binary\n",
      "0  all_hbase         s_780                     0.169802\n",
      "1  all_hbase          s_16                     0.181703\n",
      "2  all_hbase          s_80                     0.290310\n",
      "3  all_hbase         s_776                     0.221066\n",
      "4  all_hbase         s_391                     0.139891\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "records = []\n",
    "\n",
    "for x1 in os.listdir('../results'):\n",
    "    if not x1.startswith('all_hbase'):\n",
    "        continue  # пропускаем все, кто не начинается на hmin_\n",
    "    pred_dir = os.path.join('../results', x1, 'boltz_results_all', 'predictions')\n",
    "    print(pred_dir)\n",
    "    if not os.path.isdir(pred_dir):\n",
    "        continue\n",
    "    \n",
    "    for x3 in os.listdir(pred_dir):\n",
    "\n",
    "        json_path = os.path.join(pred_dir, x3, f'affinity_{x3}.json')\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path, 'r') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                    if isinstance(data, dict):\n",
    "                        # Add metadata to each record, such as folder names\n",
    "                        data['sample'] = x1\n",
    "                        data['prediction_id'] = x3\n",
    "                        records.append(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Failed to decode JSON in {json_path}\")\n",
    "        else:\n",
    "            print(f\"JSON not found: {json_path}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "df = df[['sample', 'prediction_id', 'affinity_probability_binary']]\n",
    "print(df.shape[0])\n",
    "print(df.head())\n",
    "\n",
    "os.makedirs('../results_summary', exist_ok=True)\n",
    "df.to_csv('../results_summary/all_hbase.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "217f0d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/all_hlow/boltz_results_all/predictions\n",
      "1925\n",
      "     sample prediction_id  affinity_probability_binary\n",
      "0  all_hlow         s_780                     0.331148\n",
      "1  all_hlow          s_16                     0.309124\n",
      "2  all_hlow          s_80                     0.174170\n",
      "3  all_hlow         s_776                     0.287442\n",
      "4  all_hlow         s_391                     0.137204\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "records = []\n",
    "\n",
    "for x1 in os.listdir('../results'):\n",
    "    if not x1.startswith('all_hlow'):\n",
    "        continue  # пропускаем все, кто не начинается на hmin_\n",
    "    pred_dir = os.path.join('../results', x1, 'boltz_results_all', 'predictions')\n",
    "    print(pred_dir)\n",
    "    if not os.path.isdir(pred_dir):\n",
    "        continue\n",
    "    \n",
    "    for x3 in os.listdir(pred_dir):\n",
    "\n",
    "        json_path = os.path.join(pred_dir, x3, f'affinity_{x3}.json')\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path, 'r') as f:\n",
    "                try:\n",
    "                    data = json.load(f)\n",
    "                    if isinstance(data, dict):\n",
    "                        # Add metadata to each record, such as folder names\n",
    "                        data['sample'] = x1\n",
    "                        data['prediction_id'] = x3\n",
    "                        records.append(data)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Failed to decode JSON in {json_path}\")\n",
    "        else:\n",
    "            print(f\"JSON not found: {json_path}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "df = df[['sample', 'prediction_id', 'affinity_probability_binary']]\n",
    "print(df.shape[0])\n",
    "print(df.head())\n",
    "\n",
    "os.makedirs('../results_summary', exist_ok=True)\n",
    "df.to_csv('../results_summary/all_hlow.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688f225b",
   "metadata": {},
   "source": [
    "# HLOW 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae3399d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33e53167",
   "metadata": {},
   "source": [
    "# time all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f054b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "                   step   seconds     source\n",
      "0  structure_prediction  17563.79  all_hbase\n",
      "1   affinity_prediction   9515.41  all_hbase\n",
      "2  structure_prediction   9240.51   all_hmin\n",
      "3   affinity_prediction   5571.94   all_hmin\n",
      "4  structure_prediction   6082.57   all_hlow\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df_hbase = pd.read_csv('../results/all_hbase/boltz_results_all/time.tsv', sep='\\t')\n",
    "df_hbase['source'] = 'all_hbase'\n",
    "\n",
    "df_hmin = pd.read_csv('../results/all_hmin/boltz_results_all/time.tsv', sep='\\t')\n",
    "df_hmin['source'] = 'all_hmin'\n",
    "\n",
    "df_hlow = pd.read_csv('../results/all_hlow/boltz_results_all/time.tsv', sep='\\t')\n",
    "df_hlow['source'] = 'all_hlow'\n",
    "\n",
    "combined_df = pd.concat([df_hbase, df_hmin, df_hlow], ignore_index=True)\n",
    "\n",
    "print(combined_df.shape[0])\n",
    "print(combined_df.head())\n",
    "\n",
    "os.makedirs('../results_summary', exist_ok=True)\n",
    "combined_df.to_csv('../results_summary/all_time.tsv', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5cf3b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
